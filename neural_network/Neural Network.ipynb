{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронные сети\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import wget \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data'\n",
    "url = 'http://ufldl.stanford.edu/housenumbers/train_32x32.mat'\n",
    "filename = wget.download(url)\n",
    "os.rename(filename,os.path.join(directory,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data'\n",
    "url2 = 'http://ufldl.stanford.edu/housenumbers/test_32x32.mat'\n",
    "filename2 = wget.download(url2)\n",
    "os.rename(filename2,os.path.join(directory,filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X) #layers.py/gradient_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B') \n",
    "#layers.py/gradient_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])\n",
    "#model.py/gradient_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])\n",
    "#layers.py/gradient_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30])\n",
    "\n",
    "#model.py/metrics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302705, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.300511, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302339, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301916, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301577, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301789, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302126, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303472, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302398, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302306, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303106, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303577, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302208, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301911, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301847, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302920, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302702, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302818, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303235, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302186, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "#model.py/metrics.py/optim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faaa6f5d090>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшением процесса тренировки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.282026, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.220804, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304563, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.332779, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265433, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290160, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281397, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271683, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277032, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.167511, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272940, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.312080, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292346, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.305281, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282768, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.226888, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273944, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278723, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285273, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\"\n",
    "\n",
    "#model.py/metrics.py/optim.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.318773, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300463, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.307396, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284003, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.312351, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301691, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.307653, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309887, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278664, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283250, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285759, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297113, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300555, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279871, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297075, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293508, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238663, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259315, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266430, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309123, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "#model.py/metrics.py/optim.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit на маленьком наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.331225, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.311917, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.309711, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.302350, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.290718, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.265667, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.180181, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.265704, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.124721, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.935802, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.895935, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.163137, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.727986, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.797636, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.336883, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.329628, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.978731, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.106089, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.946395, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.161467, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 2.075284, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.805114, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.584728, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.804348, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 2.109279, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.689211, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.676766, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.943303, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.628597, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.771025, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.813104, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.884957, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 2.134979, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 2.088816, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.730158, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.595846, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.690153, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.551044, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 0.898989, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.576552, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.623486, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.341393, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.264946, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.408326, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.464048, Train accuracy: 0.600000, val accuracy: 0.133333\n",
      "Loss: 1.704194, Train accuracy: 0.666667, val accuracy: 0.133333\n",
      "Loss: 1.253946, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.255594, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.340709, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.434744, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.023304, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 0.979015, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.027760, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.898096, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.640460, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.486099, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.559304, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.399684, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.402167, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.256338, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.334646, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.663623, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.633038, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.379565, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.627230, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.668342, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.287234, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.526195, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.147533, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.225693, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.921911, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.399420, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.290358, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.201694, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.131151, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.283758, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.357944, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.080966, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.211667, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.310066, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.932267, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.318413, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.586346, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.028407, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.534702, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.971755, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.760597, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.606291, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.394558, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.214189, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.729143, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.862592, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.666981, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.523661, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.275461, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.872098, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.623239, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.188035, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.257392, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.053722, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.194338, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.019591, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.843616, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.312492, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.284892, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.449362, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.601517, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.419262, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.268661, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.317647, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.379218, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.114795, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.176615, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.129002, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.406876, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.500686, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.551871, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.598201, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.179028, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.226268, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.308771, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.227681, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.560860, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.218113, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.281396, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.404934, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.427661, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.337607, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.093242, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.202814, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.205801, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.118047, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.305576, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.188596, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.306912, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.149234, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.189256, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.168980, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.492293, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.072785, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.382982, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.546748, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.247645, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.398664, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.350665, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.436692, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.199931, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.265730, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.323854, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.189928, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "#model.py/metrics.py/optim.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.343795, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.335189, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.332387, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.296897, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.327147, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.299080, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.300755, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.250714, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.206018, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.080976, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.040819, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.170397, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.150772, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.784525, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.465388, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.665627, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.181482, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.640445, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.733409, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.575550, Train accuracy: 0.400000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302544, Train accuracy: 0.077000, val accuracy: 0.078000\n",
      "Loss: 2.302596, Train accuracy: 0.193667, val accuracy: 0.204000\n",
      "Loss: 2.302199, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301464, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301374, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301646, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301090, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301504, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300259, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301779, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301069, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299484, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301234, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298077, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300449, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299050, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300888, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301022, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299452, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297772, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293022, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298543, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296681, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296087, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292540, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295392, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294263, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291945, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301614, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295358, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294888, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293147, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302564, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300742, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299366, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298420, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299979, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297920, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288009, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299561, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299619, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297112, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293347, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294926, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288526, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298033, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279660, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296981, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294832, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276019, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294873, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294221, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295985, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294633, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298043, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282489, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292483, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294164, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289722, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298239, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279918, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291000, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299193, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283668, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286485, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269856, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289689, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290886, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281848, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287309, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285697, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285175, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285788, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282489, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286593, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299929, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272194, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287523, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274780, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283190, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280918, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273986, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281080, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299520, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287403, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293634, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292905, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289408, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269455, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278439, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276457, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287015, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297300, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294212, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281081, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288730, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272713, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301745, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287308, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273839, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293608, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280053, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294042, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282923, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269104, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285030, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261899, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274830, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285336, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286366, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288578, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278352, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272822, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269680, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280022, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290470, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263144, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279861, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285617, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281874, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265243, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290360, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271502, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269280, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274407, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278161, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.294140, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281796, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271960, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289336, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286378, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303881, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278980, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281212, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285344, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277575, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285148, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272369, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278382, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275291, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266817, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274101, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289575, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291220, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301583, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280535, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266041, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270083, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292405, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266886, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245980, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280971, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268655, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270382, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273080, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281677, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253968, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267135, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282908, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254830, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254307, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288829, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257065, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265915, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292519, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270428, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274276, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270289, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260874, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271334, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258049, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284491, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271817, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279416, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272797, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288902, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260033, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287673, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250798, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279271, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268038, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266361, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287911, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268871, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274527, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275191, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278495, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284903, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223885, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254685, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272256, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277279, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268010, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.306944, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270408, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233916, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309732, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294196, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hidden_layer_size, \n",
    "                    reg = reg_strength)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=learning_rates, num_epochs=num_epochs, \n",
    "                  batch_size=batch_size, learning_rate_decay=learning_rate_decay)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "#print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa9d49b4c10>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лучшая модель на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.182000\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
